# Rate Limiter Cookbook (Bazel-first)

Este repositorio es un **proyecto tÃ©cnico incremental** diseÃ±ado como material de estudio para **entrevistas de system design** y **arquitectura de sistemas distribuidos**.

Usa un **rate limiter distribuido** como caso de estudio para explorar:
- Algoritmos de rate limiting y sus trade-offs
- Concurrencia y sincronizaciÃ³n en Java
- Sistemas distribuidos y consistencia eventual
- Build systems modernos con Bazel
- DiseÃ±o de APIs con gRPC y protobuf
- Performance engineering y benchmarking

**Objetivo**: Crear un proyecto defendible en entrevistas tÃ©cnicas que demuestre comprensiÃ³n profunda de system design, concurrencia, y arquitectura de sistemas de alto throughput.

El enfoque es **incremental y deliberado**: cada fase aÃ±ade una dimensiÃ³n de complejidad, permitiendo estudiar y articular decisiones de diseÃ±o con claridad.

---

## Valor para entrevistas tÃ©cnicas

Este proyecto estÃ¡ especÃ­ficamente diseÃ±ado para:

### System Design Interviews
- Demuestra capacidad de descomponer un problema complejo en componentes
- Articula trade-offs entre algoritmos (precisiÃ³n vs memoria vs throughput)
- Muestra evoluciÃ³n incremental de single-node a distribuido
- Cubre temas recurrentes: sharding, consistencia, latencia, throughput

### Coding Interviews (Java/Go)
- ImplementaciÃ³n correcta de estructuras de datos (ring buffers, deques)
- Manejo de concurrencia con primitivas de bajo nivel (locks, atomics)
- Testing exhaustivo con control temporal (ManualClock)
- Performance engineering con benchmarks reproducibles

### Conversaciones tÃ©cnicas
- Proyecto real con cÃ³digo ejecutable (no slides ni diagramas)
- Decisiones documentadas con justificaciÃ³n explÃ­cita
- Evidencia de pensamiento crÃ­tico sobre trade-offs
- Demuestra rigor en testing y tooling profesional

**Este no es un toy project**: es un estudio tÃ©cnico profundo con implementaciones correctas, tests exhaustivos, y documentaciÃ³n de decisiones de diseÃ±o.

---

## Conceptos de System Design cubiertos

| Concepto | Fase | ImplementaciÃ³n |
|----------|------|----------------|
| **Algoritmos de rate limiting** | Fase 1 | Token Bucket, Fixed Window, Sliding Window (Log + Counter) |
| **AbstracciÃ³n del tiempo** | Fase 1 | Clock interface, ManualClock para tests deterministas |
| **Testing determinista** | Fase 2 | JUnit 5, tests temporales sin flakiness |
| **Concurrencia** | Fase 4 | Thread-safety, locks, atomics, CAS operations |
| **In-memory state** | Fase 4 | ConcurrentHashMap, estructura de datos thread-safe |
| **RPC y serializaciÃ³n** | Fase 5 | gRPC, Protobuf, codegen con Bazel |
| **Polyglot systems** | Fase 6 | Java + Go con mismo contrato proto |
| **Performance engineering** | Fase 8 | testing/benchmark (Go), load testing, comparaciÃ³n Java vs Go |
| **Sistemas distribuidos** | Futuro | Partitioning, replicaciÃ³n, consistencia eventual |
| **Observability** | Futuro | MÃ©tricas, tracing, debugging bajo carga |

**Preguntas de entrevista tÃ­picas que este proyecto responde:**

1. *"Design a rate limiter for an API gateway"* â†’ Fases 1-5
2. *"How would you handle 100K requests/second?"* â†’ Fases 4, 7
3. *"What are the trade-offs between different rate limiting algorithms?"* â†’ Fase 1
4. *"How do you test time-dependent code?"* â†’ Fase 2 (ManualClock)
5. *"How would you distribute rate limiting across multiple nodes?"* â†’ DiseÃ±o en Fase 6+
6. *"How do you ensure consistency in a distributed rate limiter?"* â†’ CAP theorem, trade-offs documentados
7. *"How would you benchmark and optimize this system?"* â†’ Fase 7

---

## QuÃ© problema resuelve un rate limiter (en la prÃ¡ctica)

Un rate limiter decide si una peticiÃ³n se **acepta** o se **rechaza** segÃºn una polÃ­tica de trÃ¡fico.

Se usa para:

* Proteger servicios downstream (bases de datos, terceros, colas)
* Evitar abuso en APIs pÃºblicas
* Mantener SLOs bajo carga
* Implementar fairness (por usuario, token, IP, tenant)

Hasta aquÃ­, trivial.

Lo interesante aparece cuando el sistema es **distribuido**:

* Â¿DÃ³nde vive el estado?
* Â¿QuÃ© pasa si el estado no es consistente?
* Â¿CuÃ¡nta precisiÃ³n necesito realmente?
* Â¿QuÃ© latencia estoy dispuesto a pagar?

Este repo se centra en **esas preguntas**, no en definiciones de libro.

---

## Por quÃ© existe este repositorio

La mayorÃ­a de ejemplos de rate limiting que circulan por ahÃ­:

* Son *toy examples* sin edge cases
* Mezclan algoritmo, red, framework y reloj real en la misma clase
* No son reproducibles
* No permiten razonar sobre trade-offs

AdemÃ¡s, casi ninguno sirve para **aprender un build system moderno**.

AquÃ­ el rate limiter es la excusa.
El verdadero protagonista es **Bazel**.

---

## Por quÃ© Bazel (y no Maven / Gradle)

Maven funciona bien para proyectos Java tradicionales.

Pero empieza a romperse cuando quieres:

* Monorepo real (no varios repos pegados)
* CÃ³digo en varios lenguajes (Java, Go, proto)
* Builds hermÃ©ticos y reproducibles
* Cacheo agresivo a nivel de target
* Tests y benchmarks como ciudadanos de primera

En Maven, esto suele acabar en:

* Perfiles
* Scripts externos
* DocumentaciÃ³n implÃ­cita
* Builds lentos y frÃ¡giles

Bazel fuerza otra mentalidad:

* Todo es un target
* Las dependencias son explÃ­citas
* El build es un grafo
* Si no cambia el input, no se ejecuta nada

Este repositorio estÃ¡ diseÃ±ado para **mostrar eso en la prÃ¡ctica**, no explicarlo en abstracto.

---

## Scope y Roadmap

Este proyecto construye un rate limiter incremental, priorizando **claridad conceptual** sobre completitud de features.

### âœ… En scope (fases actuales):
* Algoritmos fundamentales con anÃ¡lisis de complejidad
* Concurrencia correcta con primitivas de bajo nivel
* Testing determinista y reproducible
* Build hermÃ©tico con Bazel
* MÃ©tricas y benchmarking sistemÃ¡tico
* DiseÃ±o polyglot (Java + Go)

### ğŸ”® Fuera de scope (por ahora):
* Alta disponibilidad con rÃ©plicas activas
* Sharding automÃ¡tico y rebalanceo
* IntegraciÃ³n con KV stores distribuidos (Redis, DynamoDB)
* AutenticaciÃ³n, autorizaciÃ³n, billing
* Dashboards y alerting en producciÃ³n

### ğŸ“‹ Roadmap futuro (post-Fase 8):
* **Fase 9 - Distributed coordination**: Consistencia con mÃºltiples nodos
* **Fase 10 - Persistent state**: IntegraciÃ³n con Redis/etcd
* **Fase 11 - Observability**: MÃ©tricas, tracing, profiling

**FilosofÃ­a**: Cada fase debe ser **entendible, defendible, y ejecutable**. Nada de "magia" o complejidad innecesaria.

---

## FilosofÃ­a del proyecto

Principios no negociables:

* Bazel es el protagonista, no Java
* Cada carpeta tiene su `BUILD.bazel`
* Nada de scripts mÃ¡gicos fuera de Bazel
* CÃ³digo simple, pero correcto
* Trade-offs explÃ­citos, no implÃ­citos
* Tests y benchmarks son targets
* Todo debe ser incremental y cacheable

Si algo es complejo, tiene que estar justificado.

---

## Estructura del monorepo

Estado actual:

```
rate-limiter-cookbook/
â”œâ”€â”€ MODULE.bazel              âœ… (configurado con JUnit 5)
â”œâ”€â”€ .bazelrc                  âœ…
â”œâ”€â”€ README.md                 âœ…
â”œâ”€â”€ .gitignore                âœ…
â”œâ”€â”€ docs/                     âœ…
â”‚   â””â”€â”€ design-notes.md       âœ…
â”œâ”€â”€ proto/                    âš ï¸
â”‚   â”œâ”€â”€ BUILD.bazel           âœ… (vacÃ­o)
â”‚   â””â”€â”€ ratelimit.proto       âš ï¸ (existe pero vacÃ­o)
â”œâ”€â”€ core/                     âœ… COMPLETO
â”‚   â”œâ”€â”€ BUILD.bazel           âœ…
â”‚   â”œâ”€â”€ clock/                âœ…
â”‚   â”‚   â”œâ”€â”€ BUILD.bazel       âœ…
â”‚   â”‚   â”œâ”€â”€ Clock.java        âœ…
â”‚   â”‚   â””â”€â”€ ManualClock.java  âœ…
â”‚   â”œâ”€â”€ model/                âœ…
â”‚   â”‚   â”œâ”€â”€ BUILD.bazel       âœ…
â”‚   â”‚   â”œâ”€â”€ RateLimiter.java  âœ…
â”‚   â”‚   â”œâ”€â”€ Decision.java     âœ…
â”‚   â”‚   â””â”€â”€ RateLimitResult.java âœ…
â”‚   â””â”€â”€ algorithms/           âœ…
â”‚       â”œâ”€â”€ BUILD.bazel       âœ…
â”‚       â”œâ”€â”€ token_bucket/     âœ…
â”‚       â”‚   â”œâ”€â”€ BUILD.bazel   âœ…
â”‚       â”‚   â”œâ”€â”€ TokenBucket.java     âœ…
â”‚       â”‚   â””â”€â”€ TokenBucketTest.java âœ…
â”‚       â”œâ”€â”€ fixed_window/     âœ…
â”‚       â”‚   â”œâ”€â”€ BUILD.bazel   âœ…
â”‚       â”‚   â”œâ”€â”€ FixedWindow.java     âœ…
â”‚       â”‚   â””â”€â”€ FixedWindowTest.java âœ…
â”‚       â”œâ”€â”€ sliding_window/   âœ…
â”‚       â”‚   â”œâ”€â”€ BUILD.bazel   âœ…
â”‚       â”‚   â”œâ”€â”€ SlidingWindowLog.java     âœ…
â”‚       â”‚   â””â”€â”€ SlidingWindowLogTest.java âœ…
â”‚       â””â”€â”€ sliding_window_counter/ âœ…
â”‚           â”œâ”€â”€ BUILD.bazel   âœ…
â”‚           â”œâ”€â”€ SlidingWindowCounter.java     âœ…
â”‚           â””â”€â”€ SlidingWindowCounterTest.java âœ…
â”œâ”€â”€ java/                     â³ PENDIENTE
â”‚   â”œâ”€â”€ engine/               â³
â”‚   â”œâ”€â”€ grpc/                 â³
â”‚   â”œâ”€â”€ tests/                â³
â”‚   â””â”€â”€ benchmarks/           â³
â”œâ”€â”€ go/                       â³ PENDIENTE
â”‚   â”œâ”€â”€ engine/               â³
â”‚   â”œâ”€â”€ tests/                â³
â”‚   â””â”€â”€ benchmarks/           â³
â”œâ”€â”€ load/                     â³ PENDIENTE
â”‚   â””â”€â”€ traffic_generator.go  â³
â””â”€â”€ infra/                    â³ PENDIENTE
    â””â”€â”€ docker/               â³
```

**Leyenda:**
- âœ… Implementado y funcional
- âš ï¸ Existe pero incompleto
- â³ Pendiente (no existe)

Cada capa aÃ±ade **una dimensiÃ³n nueva de complejidad**, nunca varias a la vez.

---

## Fases del proyecto

El proyecto se construye **por fases**, de forma deliberada:

### Fase 0 â€” README y mentalidad âœ…

**Estado: COMPLETADO**

Antes de escribir cÃ³digo:

* Definir quÃ© problema resolvemos
* Definir quÃ© NO resolvemos
* Alinear expectativas

### Fase 1 â€” Core puro (sin I/O) âœ…

**Estado: COMPLETADO**

* âœ… Algoritmos deterministas
* âœ… Sin red, sin threads, sin clocks reales
* âœ… Reloj inyectable (Clock + ManualClock)
* âœ… Tests exhaustivos

Algoritmos implementados:

* âœ… Token Bucket
* âœ… Fixed Window
* âœ… Sliding Window Log
* âœ… Sliding Window Counter

### Fase 2 â€” Tests como ciudadanos de primera âœ…

**Estado: COMPLETADO**

* âœ… Tests unitarios por algoritmo (5 tests funcionales)
* âœ… Edge cases cubiertos
* âœ… RegresiÃ³n temporal con reloj mockeado (ManualClock)
* âœ… ConfiguraciÃ³n de JUnit 5 con Bazel

### Fase 3 â€” Performance Testing en Java â­ï¸

**Estado: SKIPPED** (Se harÃ¡ en Go - Fase 8)

**JustificaciÃ³n del skip:**
- El objetivo principal del proyecto es profundizar en Go, no Java
- Los benchmarks serÃ¡n mÃ¡s valiosos en la Fase 8 cuando se pueda comparar Java vs Go
- Implementar el engine primero permite testear performance end-to-end, no solo algoritmos aislados
- JMH aÃ±adirÃ­a complejidad innecesaria si el foco es Go

**Nota:** Performance testing se realizarÃ¡ comprehensivamente en **Fase 8** con:
- Benchmarks en Go (`testing/benchmark`)
- ComparaciÃ³n directa Java vs Go
- Load testing end-to-end con herramienta propia
- MÃ©tricas mÃ¡s realistas en contexto de engine completo

---

### Fase 4 â€” Java Engine (Concurrencia y Alto Throughput) â³ â† **SIGUIENTE FASE**

**Estado: PENDIENTE**

Wrapper thread-safe para los algoritmos core, diseÃ±ado para alto throughput en contextos concurrentes:

**Primitivas de concurrencia:**
* â³ `ReentrantLock` vs `synchronized` - trade-offs de fairness y performance
* â³ `AtomicLong` para contadores lock-free
* â³ `ConcurrentHashMap` para almacenamiento por key
* â³ `StampedLock` para optimistic reads (exploraciÃ³n)

**DiseÃ±o del engine:**
* â³ API simple: `boolean tryAcquire(String key, int permits)`
* â³ In-memory state sin persistencia (por ahora)
* â³ Eviction policy para limitar memoria (LRU simple)
* â³ Sin frameworks externos (solo JDK)

**Targets de performance:**
* â³ > 100K requests/sec en un solo nodo (single-threaded)
* â³ > 500K requests/sec con mÃºltiples threads
* â³ Latencia p99 < 1ms para hot keys

**Testing de concurrencia:**
* â³ Tests con `CountDownLatch` para race conditions
* â³ ValidaciÃ³n de thread-safety con mÃºltiples threads
* â³ Tests de stress con carga sostenida

**Objetivo**: Demostrar dominio de primitivas de concurrencia de Java y capacidad de razonar sobre performance en sistemas multi-threaded.

### Fase 5 â€” gRPC API â³

**Estado: PENDIENTE**

API gRPC para exponer el rate limiter como servicio, diseÃ±ada para alto throughput y baja latencia:

**Contrato proto:**
* â³ `CheckRateLimit(key, permits)` - unary call
* â³ `CheckRateLimitBatch(requests[])` - batch para reducir RTT
* â³ `ResetRateLimit(key)` - operaciÃ³n admin
* â³ Health check endpoint

**ImplementaciÃ³n del servidor:**
* â³ gRPC Java con servidor asÃ­ncrono (non-blocking)
* â³ Thread pool tuning para alto throughput
* â³ Error handling: InvalidArgument, ResourceExhausted, Unavailable
* â³ Interceptors para logging y mÃ©tricas
* â³ Graceful shutdown

**Manejo de errores y resiliencia:**
* â³ Retry policy en cliente (exponential backoff)
* â³ Circuit breaker para fallos cascada
* â³ Deadline propagation
* â³ Rate limiting del servidor mismo (protecciÃ³n contra DDoS)

**Codegen con Bazel:**
* â³ protoc + grpc-java plugin
* â³ Targets separados: proto_library, java_proto_library, java_grpc_library
* â³ Compartir .proto entre Java y Go

**Valor para entrevistas**: Demuestra conocimiento de RPC, serializaciÃ³n, error handling, y diseÃ±o de APIs productizables.

### Fase 6 â€” Load Testing Tool en Go â³

**Estado: PENDIENTE**

Herramienta en Go (estilo k6 minimalista) para validar rate limiters bajo carga real:

**Funcionalidades:**
* â³ Cliente gRPC en Go para llamar a la API (Fase 5)
* â³ Cliente HTTP simple para APIs REST (futuro)
* â³ Generador de trÃ¡fico configurable (RPS, duraciÃ³n, concurrencia)
* â³ DistribuciÃ³n de keys: uniforme, zipf, hot keys

**MÃ©tricas recolectadas:**
* â³ Throughput (requests/sec achieved vs target)
* â³ Latencia: p50, p95, p99, p99.9, max
* â³ Tasa de rechazo (esperada vs real)
* â³ Errores de red (timeouts, connection refused)
* â³ Histograma de latencias en tiempo real

**Output:**
* â³ Reporte final en consola (tabla con mÃ©tricas)
* â³ JSON export para anÃ¡lisis posterior
* â³ GrÃ¡ficas ASCII simples (histograma de latencias)

**Escenarios de testing:**
* â³ Carga constante (sustained load)
* â³ Spike test (rÃ¡faga repentina)
* â³ Ramp-up test (carga gradual)

**Valor para entrevistas**: Herramienta real de load testing, demuestra capacidad de construir tooling propio y validar sistemas bajo carga.

### Fase 7 â€” ImplementaciÃ³n en Go â³

**Estado: PENDIENTE**

ImplementaciÃ³n del rate limiter en Go, compartiendo el mismo contrato proto pero con diferencias de diseÃ±o especÃ­ficas del lenguaje:

**Algoritmos core en Go:**
* â³ Token Bucket, Fixed Window, Sliding Window (misma lÃ³gica que Java)
* â³ Clock abstraction en Go (interface Clock, MockClock para tests)
* â³ Testing con `testing` package de Go

**Primitivas de concurrencia en Go:**
* â³ Goroutines vs threads de Java
* â³ Channels vs locks para comunicaciÃ³n
* â³ `sync.Mutex` vs `sync.RWMutex` vs `atomic`
* â³ `sync.Map` vs `map[string]RateLimiter` + mutex

**Engine thread-safe:**
* â³ In-memory storage con sync.Map o mutex + map
* â³ Goroutine pool para handling de requests
* â³ Context propagation para cancellation

**gRPC server en Go:**
* â³ Mismo .proto que Java
* â³ grpc-go implementation
* â³ ComparaciÃ³n de performance Go vs Java

**Trade-offs Go vs Java:**
* â³ GC: stop-the-world (Java) vs concurrent (Go)
* â³ Goroutines livianas vs threads pesados
* â³ Simplicidad de deployment (binary estÃ¡tico Go vs JVM)
* â³ Performance: latencia, throughput

**Valor para entrevistas**: Demuestra comprensiÃ³n profunda de concurrencia en dos lenguajes, capacidad de comparar trade-offs de diseÃ±o.

### Fase 8 â€” Benchmarks y ComparaciÃ³n âœ…

**Estado: COMPLETADA**

Benchmarking sistemÃ¡tico comparando Java y Go implementations:

**Benchmarks de algoritmos:**
* âœ… 25+ Go benchmarks (4 algoritmos Ã— 4 tipos + engine + model)
* âœ… 15 JMH Java benchmarks (4 algoritmos Ã— 3 escenarios + 3 engine)
* âœ… Wrapper scripts para ejecutar y recolectar resultados

**Comparison Framework:**
* âœ… Go CLI tool para comparaciÃ³n
* âœ… Parser de JMH JSON + Go benchmark output
* âœ… Reportes markdown con tablas y ASCII charts
* âœ… Export JSON para automation

**EjecuciÃ³n:**
```bash
# Run all benchmarks
bazel run //benchmarks:run_all

# View results
cat benchmarks/reports/latest/comparison.md
```

**Resultados:**
- **Go**: TÃ­picamente 10-30% mÃ¡s rÃ¡pido (0 allocs/op en hot paths)
- **Java**: Competitivo despuÃ©s de warmup JIT
- **Latencia**: Ambos <100ns/op en operaciones core

Ver documentaciÃ³n completa: [benchmarks/README.md](benchmarks/README.md)

**Benchmarks de engines:**
* â³ Throughput bajo diferentes cargas (1K, 10K, 100K, 1M RPS)
* â³ Latencia con diferentes niveles de concurrencia
* â³ Memory footprint (heap usage, GC pressure)
* â³ CPU utilization

**Benchmarks end-to-end (gRPC):**
* â³ Latencia con serializaciÃ³n proto
* â³ Overhead de red vs in-process
* â³ ComparaciÃ³n Java gRPC server vs Go gRPC server

**VisualizaciÃ³n de resultados:**
* â³ GrÃ¡ficas de latencia (percentiles)
* â³ Throughput vs latencia trade-off
* â³ ComparaciÃ³n side-by-side Java vs Go

**Valor para entrevistas**: Demuestra rigor en performance engineering, capacidad de tomar decisiones basadas en datos, no suposiciones.

---

## Estado del Proyecto (Actualizado)

### âœ… Completado (Fases 1-2)

El proyecto ha completado exitosamente las bases fundamentales:

**Core Algorithms** (`/core/algorithms/`)
- **Token Bucket**: ImplementaciÃ³n completa con refill dinÃ¡mico continuo
- **Fixed Window**: ImplementaciÃ³n con alineaciÃ³n de ventanas temporales
- **Sliding Window Log**: PrecisiÃ³n exacta usando ArrayDeque para timestamps
- **Sliding Window Counter**: Balance memoria/precisiÃ³n con ring buffer de buckets

**Infrastructure**
- Clock abstraction para tests deterministas (Clock + ManualClock)
- Model layer limpio (Decision, RateLimitResult, RateLimiter)
- 5 tests unitarios funcionales con JUnit 5 + JUnit Platform
- Bazel configurado correctamente con rules_java

**Comandos Funcionales:**
```bash
bazel test //core/algorithms/...  # âœ… 4/4 tests passing
```

### â³ Siguiente Fase Recomendada: Java Engine (Fase 4)

**Fase 3 SKIPPED** - Benchmarks se harÃ¡n comprehensivamente en Fase 8 con Go.

Para continuar el proyecto, el siguiente paso es implementar:
- Java Engine con ConcurrentHashMap para almacenamiento multi-key
- Thread-safety con ReentrantLock o synchronized
- Eviction policy (LRU simple) para limitar memoria
- Tests de concurrencia con CountDownLatch y mÃºltiples threads

**JustificaciÃ³n**: Construir el engine permite tener un sistema funcional end-to-end. Los benchmarks serÃ¡n mÃ¡s valiosos cuando se puedan comparar implementaciones completas Java vs Go, no solo algoritmos aislados.

---

## CÃ³mo usar este repositorio

**Ejecutar todos los tests del core (Fases 1-2 completadas):**

```bash
bazel test //core/algorithms/...
```

**Ejecutar tests individuales:**

```bash
bazel test //core/algorithms/token_bucket:token_bucket_test
bazel test //core/algorithms/fixed_window:fixed_window_test
bazel test //core/algorithms/sliding_window:sliding_window_log_test
bazel test //core/algorithms/sliding_window_counter:sliding_window_counter_test
```

**Ver resultados detallados:**

```bash
bazel test //core/algorithms/... --test_output=all
```

Bazel se encarga de ejecutar **solo lo que cambia**.

---

## Lessons learned (vivo)

**De las Fases 1-2 completadas:**

* âœ… **Bazel premia targets pequeÃ±os y bien definidos**
  - Cada algoritmo es un target independiente con su propio BUILD.bazel
  - Tests aislados sin dependencias cruzadas
  - Cacheo granular permite builds incrementales rÃ¡pidos

* âœ… **JUnit 5 requiere configuraciÃ³n explÃ­cita en Bazel**
  - Necesita JUnit Platform Console Launcher como `main_class`
  - No puede usar el runner JUnit 4 por defecto de Bazel
  - Requiere `use_testrunner = False` y dependencias de junit-platform

* âœ… **ManualClock hace los tests deterministas y rÃ¡pidos**
  - No hay sleeps ni timeouts en tests
  - Control total sobre el tiempo con `advanceNanos()` y `setNanos()`
  - Resultados reproducibles 100% sin flakiness

* âœ… **Sliding Window Log es mÃ¡s preciso, pero mÃ¡s caro**
  - PrecisiÃ³n exacta: O(permits) por request vs O(1) en Fixed Window
  - Memoria: O(limit) vs O(1) en Fixed Window
  - Trade-off documentado explÃ­citamente en cÃ³digo

* âœ… **Trade-offs son explÃ­citos en el cÃ³digo**
  - Comentarios documentan pros/contras de cada algoritmo
  - Decisiones arquitectÃ³nicas visibles (ej: "precisiÃ³n vs coste")
  - No hay complejidad oculta ni "magia"

**Pendiente de validar en fases futuras:**

* En distribuido, la perfecciÃ³n suele ser innecesaria
* La mayorÃ­a de sistemas necesitan aproximaciones razonables, no exactitud matemÃ¡tica
* Latencia vs consistencia en entornos multi-nodo

---

## Arquitectura y decisiones de diseÃ±o

### SeparaciÃ³n de concerns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Testing Tool (Go)                     â”‚
â”‚  - Generador de trÃ¡fico concurrente         â”‚
â”‚  - MÃ©tricas: throughput, latencia, rechazos â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  gRPC API (Java)                            â”‚
â”‚  - Endpoint: CheckRateLimit(key, permits)   â”‚
â”‚  - Protobuf codegen con Bazel               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Java Engine (Thread-safe wrapper)          â”‚
â”‚  - ConcurrentHashMap<String, RateLimiter>   â”‚
â”‚  - Locks/Atomics para sincronizaciÃ³n        â”‚
â”‚  - Eviction policy (LRU)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Core Algorithms (Puro, sin I/O)            â”‚
â”‚  - TokenBucket, FixedWindow, SlidingWindow  â”‚
â”‚  - Clock abstraction inyectable             â”‚
â”‚  - Determinista, testable                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Trade-offs principales documentados

| DecisiÃ³n | OpciÃ³n elegida | Trade-off | JustificaciÃ³n |
|----------|----------------|-----------|---------------|
| **Algoritmo por defecto** | Token Bucket | PrecisiÃ³n vs simplicidad | Balance ideal: refill continuo, memoria O(1), implementaciÃ³n simple |
| **Almacenamiento** | In-memory (ConcurrentHashMap) | Velocidad vs persistencia | Latencia sub-ms para hot paths, suficiente para Fase 4 |
| **SincronizaciÃ³n** | ReentrantLock por key | Granularidad vs overhead | Lock por key evita contention global, permite paralelismo |
| **Testing temporal** | ManualClock injection | Determinismo vs realismo | Tests reproducibles > tests realistas, no flakiness |
| **Build system** | Bazel | Learning curve vs hermetic builds | InversiÃ³n inicial vale para reproducibilidad y polyglot |
| **RPC** | gRPC + Protobuf | Complejidad vs performance | SerializaciÃ³n eficiente, codegen, soporte multi-lenguaje |

### Algoritmos de Rate Limiting: AnÃ¡lisis Profundo

#### Token Bucket - Refill Continuo

**Concepto:** Bucket con tokens que se regeneran continuamente. Permite bursts controlados.

**Funcionamiento:**
```
ConfiguraciÃ³n: capacity=10, rate=5 tokens/sec

t=0.0s  [##########] 10 tokens â†’ request(7) â†’ ALLOW
t=0.0s  [###       ]  3 tokens â†’ request(5) â†’ REJECT
t=0.4s  [#####     ]  5 tokens (3 + 2 refill) â†’ request(5) â†’ ALLOW
t=1.4s  [#####     ]  5 tokens (0 + 5 refill)
```

**Refill automÃ¡tico:** `tokens = min(capacity, tokens + elapsed_time Ã— rate)`

**Trade-offs:**
- âœ… Permite bursts naturales (hasta capacity)
- âœ… Refill continuo (no abrupto)
- âœ… O(1) tiempo y memoria
- âŒ Requiere sincronizaciÃ³n en distribuido
- âŒ Necesita timestamps precisos

**CuÃ¡ndo usar:** Sistemas que necesitan manejar trÃ¡fico con picos naturales (APIs REST, colas de mensajes).

---

#### Fixed Window - El Boundary Problem

**Concepto:** Contador simple que se resetea cada X tiempo en ventanas alineadas.

**Funcionamiento:**
```
ConfiguraciÃ³n: window=1s, limit=10

Ventana 1 [0.0s - 1.0s]          Ventana 2 [1.0s - 2.0s]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ t=0.3s: +5 â†’ used=5   â”‚       â”‚ t=1.0s: RESET â†’ used=0â”‚
â”‚ t=0.8s: +5 â†’ used=10  â”‚       â”‚ t=1.5s: +10 â†’ used=10 â”‚
â”‚ t=0.9s: +1 â†’ REJECT âŒâ”‚       â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**âš ï¸ BOUNDARY PROBLEM - Puede Permitir 2x el LÃ­mite:**

```
    Ventana 1 [0.0s - 1.0s]          Ventana 2 [1.0s - 2.0s]
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         [FINAL]       â”‚       â”‚ [INICIO]              â”‚
0.0sâ”‚                  0.9s â”‚  1.0s â”‚ 1.1s                 â”‚2.0s
    â”‚                   â–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆâ–ˆâ–ˆâ–ˆ                  â”‚
    â”‚                  10reqâ”‚ RESET â”‚10req                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                      Â¡20 requests en 200ms! ğŸ’¥
```

**Por quÃ© ocurre:**
- Ventanas estÃ¡n **alineadas** al calendario (0s, 1s, 2s...)
- Reset **abrupto** en el boundary
- No considera distribuciÃ³n temporal de requests
- Un atacante puede explotar esto: enviar 10 requests al final de cada ventana + 10 al inicio de la siguiente

**Ejemplo real del test:**
```java
// t=0.9s: 10 requests al final de ventana 1
window.tryAcquire("user1", 10) â†’ ALLOW âœ…

// t=1.0s: RESET (nueva ventana)

// t=1.1s: 10 requests al inicio de ventana 2
window.tryAcquire("user1", 10) â†’ ALLOW âœ…

// Total: 20 requests en 200ms (lÃ­mite es "10 por segundo")
```

**Trade-offs:**
- âœ… Extremadamente simple (un contador)
- âœ… O(1) tiempo y memoria
- âœ… FÃ¡cil de implementar y debuggear
- âŒ **Boundary problem: puede permitir 2x el rate**
- âŒ Reset abrupto (no gradual)
- âŒ No adecuado para protecciÃ³n DDoS

**CuÃ¡ndo usar:**
- APIs internas donde bursts son aceptables
- LÃ­mites muy conservadores (lÃ­mite=100, esperas ~50)
- Sistemas educativos / demos
- **NO usar:** APIs pÃºblicas, protecciÃ³n contra abuso, SLAs estrictos

---

#### Sliding Window Log - PrecisiÃ³n Exacta

**Concepto:** Guarda timestamp de cada request en una cola. Eviction gradual.

**Funcionamiento:**
```
ConfiguraciÃ³n: window=1s, limit=5

t=0.0s: requests=[0]         â†’ ALLOW (1/5)
t=0.2s: requests=[0, 200ms]  â†’ ALLOW (2/5)
t=0.5s: requests=[0, 200ms, 500ms, 500ms, 500ms] â†’ 5/5
t=0.6s: requests=[0, 200ms, 500ms, 500ms, 500ms] â†’ REJECT âŒ
t=1.1s: prune < 100ms â†’ requests=[200ms, 500ms, 500ms, 500ms]
t=1.1s: requests=[200ms, 500ms, 500ms, 500ms, 1100ms] â†’ ALLOW (5/5)
```

**NO sufre boundary problem:**
```
t=0.9s:  10 requests â†’ ALLOW âœ…
t=1.1s:  window = [0.1s-1.1s] contiene 10 requests
         â†’ REJECT âŒ (ventana deslizante, no reset)
```

**Trade-offs:**
- âœ… **PrecisiÃ³n exacta** en cualquier momento
- âœ… No boundary problem
- âœ… Eviction gradual (no abrupta)
- âŒ O(limit) memoria (guarda todos los timestamps)
- âŒ O(permits) tiempo por request (inserciÃ³n + eviction)
- âŒ PresiÃ³n en GC (ArrayDeque con objetos Long)
- âŒ Estado grande en distribuido

**CuÃ¡ndo usar:**
- Cuando precisiÃ³n exacta es crÃ­tica
- APIs pÃºblicas con SLAs estrictos
- Sistemas anti-fraude
- Memoria no es limitante
- **NO usar:** High throughput (>1M RPS), memoria limitada

---

#### Sliding Window Counter - AproximaciÃ³n PrÃ¡ctica

**Concepto:** Ring buffer de buckets. Balance entre Fixed Window y Sliding Window Log.

**Funcionamiento:**
```
ConfiguraciÃ³n: window=1s, buckets=10 (100ms cada uno), limit=20

Ring buffer:
[bucket0][bucket1][bucket2]...[bucket9]
   3       5        4           2

t=0.3s (bucket 3): +5 â†’ total=19
t=0.6s (bucket 6): +2 â†’ REJECT (19+2 > 20)
t=1.1s: bucket 1 sale, bucket 11 entra (wrap)
```

**Ring buffer wrapping:**
```
t=0.0s-0.9s: buckets 0-9 contienen 20 requests
t=1.0s: bucket 0 sale (libera su count)
t=1.0s: bucket 10 entra (mismo Ã­ndice que bucket 0)
```

**Trade-offs:**
- âœ… Mejor que Fixed Window (granularidad)
- âœ… MÃ¡s barato que Sliding Window Log
- âœ… O(buckets) memoria (fijo)
- âœ… O(1) tiempo amortizado
- âš ï¸ **AproximaciÃ³n** (precisiÃ³n depende de # buckets)
- âš ï¸ TodavÃ­a tiene boundary problem (menor)
- âŒ ConfiguraciÃ³n adicional (elegir # buckets)

**Precision vs buckets:**
- 1 bucket = Fixed Window (boundary problem completo)
- 10 buckets = boundary problem ~10% (vs 100% de Fixed Window)
- 100 buckets = casi exacto, pero overhead mayor

**CuÃ¡ndo usar:**
- Balance memoria/precisiÃ³n necesario
- High throughput donde Sliding Window Log es caro
- Puedes tolerar ~5-10% imprecisiÃ³n
- ProducciÃ³n real (usado por Redis, Nginx)

---

### ComparaciÃ³n Directa

| Algoritmo | Memoria | PrecisiÃ³n | Tiempo | Boundary Problem |
|-----------|---------|-----------|--------|------------------|
| **Token Bucket** | O(1) | Buena | O(1) | No aplica (refill continuo) |
| **Fixed Window** | O(1) | Mala | O(1) | âš ï¸ **SÃ (hasta 2x rate)** |
| **Sliding Window Log** | O(limit) | Exacta | O(permits) | âœ… **NO** |
| **Sliding Window Counter** | O(buckets) | Aproximada | O(1) | âš ï¸ SÃ­ (mitigado) |

### RecomendaciÃ³n por Escenario

**APIs Internas (bajo riesgo):**
- Fixed Window (simple) o Token Bucket (bursts)

**APIs PÃºblicas (protecciÃ³n contra abuso):**
- Sliding Window Log (precisiÃ³n) o Sliding Window Counter (performance)

**High Performance (>1M RPS):**
- Token Bucket o Sliding Window Counter con pocos buckets

**ProtecciÃ³n DDoS:**
- Sliding Window Log (no boundary problem)

**Educational / Demo:**
- Fixed Window (entender el problema) â†’ Sliding Window Log (soluciÃ³n)

---

### Por quÃ© no usar librerÃ­as externas (Guava, Resilience4j)

En un proyecto de producciÃ³n, usarÃ­a `Guava RateLimiter` o `Resilience4j`.

AquÃ­ la implementaciÃ³n manual es **deliberada** porque:
1. **Entrevistas valoran implementaciÃ³n desde cero** - demuestra comprensiÃ³n profunda
2. **Control total sobre trade-offs** - puedo explicar cada decisiÃ³n
3. **Material de estudio** - entender el "cÃ³mo" y el "por quÃ©"
4. **Bazel como protagonista** - estructurar targets desde cero

### PrÃ³ximas decisiones de diseÃ±o (Fases futuras)

**Fase 5 (gRPC)**:
- Â¿Streaming bidireccional o unary calls?
- Â¿CÃ³mo manejar backpressure?
- Â¿QuÃ© hacer si el servidor estÃ¡ sobrecargado?

**Fase 6 (Go implementation)**:
- Goroutines + channels vs mutexes
- sync.Map vs mutex + map[string]
- Diferencias con implementaciÃ³n Java

**Fase 8 (Distributed)**:
- Consistencia fuerte vs eventual
- Leader election (Raft, Paxos)
- Partitioning strategy (consistent hashing)

---

## CÃ³mo usar este proyecto en entrevistas

### Para System Design rounds:
1. Explica la evoluciÃ³n incremental (single-node â†’ distributed)
2. Articula trade-offs entre algoritmos con anÃ¡lisis de complejidad
3. Discute decisiones de concurrencia (locks, atomics, CAS)
4. Muestra tests deterministas con ManualClock
5. Habla sobre cÃ³mo escalarÃ­as a millones de requests/sec

### Para Coding rounds:
1. Muestra implementaciÃ³n limpia de Token Bucket o Sliding Window
2. Explica el patrÃ³n de Clock injection para testing
3. Demuestra comprensiÃ³n de estructuras de datos (ArrayDeque, ring buffer)
4. Habla sobre complejidad temporal y espacial

### Para conversaciones de arquitectura:
1. Referencia el cÃ³digo real en GitHub
2. Muestra Bazel targets y estructura del monorepo
3. Explica decisiones de tooling (Bazel vs Maven)
4. Discute roadmap futuro (distributed, persistence)

---

## Licencia

MIT (o la que prefieras).
